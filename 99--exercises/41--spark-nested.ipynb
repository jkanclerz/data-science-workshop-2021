{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/data-science-workshop-2021/blob/main/99--exercises/41--spark-nested.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz -O spark-3.2.0-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.2.0-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "```json\n",
    "{\n",
    "  imie,\n",
    "  nazwisko,\n",
    "  wiek,\n",
    "  plec,\n",
    "  dom: {\n",
    "    ulica,\n",
    "    numer_domu,\n",
    "    kod_pocztowy,\n",
    "    miasto,\n",
    "    wojewodztwo,\n",
    "    telefon\n",
    "  },\n",
    "  praca: {\n",
    "    firma,\n",
    "    stanowisko,\n",
    "    ulica,\n",
    "    numer_domu,\n",
    "    kod_pocztowy,\n",
    "    miasto,\n",
    "    telefon,\n",
    "    wynagrodzenie\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q pyspark findspark faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faker\n",
    "import random\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "N_PROBS = 2000\n",
    "  \n",
    "def generate_person(f):\n",
    "    \n",
    "    plec = f.random_element(elements=(\"K\", \"M\"))\n",
    "    if plec == 'M':\n",
    "        imie = f.first_name_male()\n",
    "        nazwisko = f.last_name_male()\n",
    "    else:\n",
    "        imie = f.first_name_female()\n",
    "        nazwisko = f.last_name_female()\n",
    "    wiek = random.randint(25, 65)\n",
    "    person = {\n",
    "        'imie': imie,\n",
    "        'nazwisko': nazwisko,\n",
    "        'wiek': wiek,\n",
    "        'plec': plec,\n",
    "        'dom': {\n",
    "            'ulica': f.street_name(),\n",
    "            'numer_domu': f.building_number(),\n",
    "            'kod_pocztowy': f.postcode(),\n",
    "            'miasto': f.city(),\n",
    "            'wojewodztwo': f.region(),\n",
    "            'telefon': f.phone_number()\n",
    "        },\n",
    "        'praca': {\n",
    "            'firma': f.company(),\n",
    "            'stanowisko': f.job(),\n",
    "            'ulica': f.street_name(),\n",
    "            'numer_domu': f.building_number(),\n",
    "            'kod_pocztowy': f.postcode(),\n",
    "            'miasto': f.city(),\n",
    "            'telefon': f.phone_number(),\n",
    "            'wynagrodzenie': 200 * wiek + 100 * random.randint(-5, 5)\n",
    "        }\n",
    "    }\n",
    " \n",
    "    return person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p employees_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = faker.Faker(['pl_PL'])\n",
    "for i in range(N_PROBS):\n",
    "    osoba = generate_person(fake)\n",
    "    with open(\"employees_dataset/%04d.json\" % (i+1), \"w\") as file:\n",
    "        json.dump(osoba, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/11 07:47:00 WARN Utils: Your hostname, Jakubs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.8.8 instead (on interface en0)\n",
      "21/12/11 07:47:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/jkanclerz/myplace/dydaktyka/przetwarzanie-dokumnetow/data-science-workshop-2021/40--spark/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/11 07:47:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "21/12/11 07:47:02 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Test it\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+----+--------------------+----+\n",
      "|                 dom| imie|nazwisko|plec|               praca|wiek|\n",
      "+--------------------+-----+--------+----+--------------------+----+\n",
      "|{52-454, Koło, 46...|Liwia|  Łudzik|   K|{Grupa Morys, 24-...|  41|\n",
      "+--------------------+-----+--------+----+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"employees_dataset/0001.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dom: struct (nullable = true)\n",
      " |    |-- kod_pocztowy: string (nullable = true)\n",
      " |    |-- miasto: string (nullable = true)\n",
      " |    |-- numer_domu: string (nullable = true)\n",
      " |    |-- telefon: string (nullable = true)\n",
      " |    |-- ulica: string (nullable = true)\n",
      " |    |-- wojewodztwo: string (nullable = true)\n",
      " |-- imie: string (nullable = true)\n",
      " |-- nazwisko: string (nullable = true)\n",
      " |-- plec: string (nullable = true)\n",
      " |-- praca: struct (nullable = true)\n",
      " |    |-- firma: string (nullable = true)\n",
      " |    |-- kod_pocztowy: string (nullable = true)\n",
      " |    |-- miasto: string (nullable = true)\n",
      " |    |-- numer_domu: string (nullable = true)\n",
      " |    |-- stanowisko: string (nullable = true)\n",
      " |    |-- telefon: string (nullable = true)\n",
      " |    |-- ulica: string (nullable = true)\n",
      " |    |-- wynagrodzenie: long (nullable = true)\n",
      " |-- wiek: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"employees_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+----+--------------------+----+\n",
      "|                 dom|    imie|  nazwisko|plec|               praca|wiek|\n",
      "+--------------------+--------+----------+----+--------------------+----+\n",
      "|{01-253, Świętoch...|Krystyna|  Wylegała|   K|{Dziedzina-Polito...|  27|\n",
      "|{77-216, Grudziąd...|  Fabian|Szczubełek|   M|{Spółdzielnia Gra...|  51|\n",
      "|{58-990, Sandomie...|   Kamil|    Konrad|   M|{Spółdzielnia Klę...|  26|\n",
      "+--------------------+--------+----------+----+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|kod_pocztowy|kod_pocztowy|\n",
      "+------------+------------+\n",
      "|      01-253|      21-443|\n",
      "|      77-216|      38-365|\n",
      "|      58-990|      75-408|\n",
      "|      53-177|      59-578|\n",
      "|      15-943|      78-660|\n",
      "+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .select(\n",
    "        F.col('dom.kod_pocztowy'),\n",
    "        F.col('praca.kod_pocztowy'),\n",
    "    )\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_we_need_for_modeling_df = df.select('wiek',F.col('praca.wynagrodzenie').alias('wynagrodzenie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf employees.parquet employees-by-age.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_we_need_for_modeling_df.write.parquet('employees.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_we_need_for_modeling_df\\\n",
    "    .repartition(1)\\\n",
    "    .write\\\n",
    "    .partitionBy(\"wiek\")\\\n",
    "    .parquet('employees-by-age.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
